# Sprouts Nikki

## 第一周

### #1 Feb 10
今天部署了 Pytorch 环境，补全了自己的深度学习基础知识。学习了 tensor 类的索引、切片、内存分配、GPU使用等操作。并通过代码实践搞懂了张量的轴这一概念（axis）。此外，学习了梯度，上手证明了李沐老师教材中的一些数学结论。了解了自动求导的原理（计算图，以及衍生出的正向/反向传播）。结合以前学习c++时了解的内存知识，初步建立起了内存分配的想法。
### #2 Feb 11
在没看李沐老师讲解的情况下，自己尝试实现了一个简单的线性回归模型，实现了前向计算和反向传播。理解了整个模型构建的流程。
### #3 Feb 12
跟随李沐老师的讲解实现了线性回归模型。
### #4 Feb 13
休息
### #5 Feb 14
累死了，只看了点softmax
### #6 Feb 15
softmax完结
### #7 Feb 16
顶多看一点论文开头

### 周总结
本周主要完成了深度学习所需环境的搭建以及深度学习基础的学习。首先，本周掌握了 PyTorch 库的一些基本使用方法，tensor 类的索引、切片、内存分配、GPU使用等操作。并通过代码实践搞懂了张量的axis这一概念。此外，学习了梯度，并尝试证明了李沐老师教材中的求梯度公式。在学习 PyTorch 的过程中，我结合以前学习C++的内存部分章节时的知识，了解到了内存分配的重要性以及 PyTorch 中张量的内存分配方式，开始理解深度学习过程中处理内存分配的想法和重要性。

此外，为了给后续的学习打下基础，本周还用torch学习并实现了线性回归和softmax回归。通过这两个模型，我大概了解到了深度学习模型搭建的基本思路：对于处理后的数据，采用一个模型（从而选定建模所用的函数和参数），并定义一个损失函数，用于指导参数更新的“方向”，从而完成训练过程，最后再通过精确率或统计误差等统计量来衡量模型的好坏。相比传统的机器学习，深度学习多出了损失函数和参数更新的环节，并给出了寻找更有效的参数的方法：梯度下降法。

最后，本周初步阅读了DDPM的论文，了解了DDPM的核心思想，也就是逐步加入噪声（前向），然后让模型逐步去噪（反向）。

下周任务：往后学习多层感知机，深化对深度学习的理解，同时继续阅读DDPM的论文。交替学习基础和论文。

## 第二周
### #8 Feb 17
阅读了GAN的论文。
### #9 Feb 18
学习了MLP的原理，阅读了VAE的论文。
### #10 Feb 19
学懂了VAE

### 周总结
本周先学习了多层感知机的基础，略读了GAN，VAE的原理和论文，细读了DDPM这篇论文，并推导了其中的大部分公式。在MLP的学习过程中了解到了MLP的基本架构以及重要概念：隐藏层和激活函数。并在后续的学习过程中了解了一些如何处理过拟合的方法，比如以约束参数为基本思想的正则化方法（又分为直接约束参数值的权重衰减法和通过改变神经网络结构避免过拟合的dropout法）。在学完MLP后我彻底理解了深度学习中常说的“前向和反向”两个概念，加深了对DL流程的理解。以上的学习都为接下来三篇论文的阅读打下了基础。
在图像生成的工作中，我们的流程往往是训练一个神经网络，让它能够生成一个概率分布去逼近原有图像的概率分布，再进行参数更新。而真实的概率分布往往十分复杂，因此需要建立一些模型来简化这一过程。比如，GAN采用一个对抗网络通过minmax博弈训练生成器和判别器，从而绕开了对原有概率分布的直接建模；但其缺点也十分明显————没有传统意义上的“损失函数”，从而没有一种客观的衡量来评判图像生成好坏的程度。VAE采用的方法是对隐变量进行建模，它假设图像x的生成由隐变量z控制，以此定义一个负责学习后验分布的编码器和学习先验分布的解码器。最后通过KL散度来衡量损失函数。VAE的数学技巧与DDPM也比较相似，都用到了变分推断和重参数化技巧，我认为这两点是十分重要的，尤其是重参数化技巧在后续的工作（DDPM）中也起到了十分重要的作用。
DDPM的核心流程是“前向加噪，后向去噪”，在马尔可夫性质下，可以证明原图像经历一系列正态分布的转移后，最终会迭代为一个简单的正态分布，这就是前向的过程。而后向考虑的也是在马尔可夫性质下，利用一系列正态分布去逼近原始的图片。在讨论损失函数时，作者的思路十分巧妙，先定义负对数似然，然后利用变分推断化为证据下界（ELBO），之后通过马尔可夫性质（引入q分布）转化为一系列正态分布的KL散度之和，这样问题就从研究复杂分布变为了研究正态分布的均值（该KL散度有解析解），最后再利用重参数化技巧，把问题变为预测噪声，因此整个损失函数化为了噪声ε的MSE。这篇文章的高光点不仅在于提出了一种全新的编码器，更在于给出了一种新的损失函数。
详细笔记：https://github.com/PeiyangFantasist/Learn-Notes-of-DL-and-CV
下周任务：试着阅读DDIM论文，并尝试跟着hugging face上的教程学习扩散模型的代码实现。

## 第三周
### 周总结
本周在本地复现了DDPM的代码，执行了一次模型训练。在学习中了解到了位置编码的实现思路，理解了DDPM是如何把时间步作为参数传给神经网络的。同时，为了完成神经网络的搭建，我还学习了残差神经网络(ResNet)和U-Net。残差神经网络通过引入跳跃连接————即让中间层的学习目标变更为残差函数，从而避免了梯度消失和网络退化的问题，解决了深层网络的性能劣于浅层网络的问题。而U-Net则通过上下采样的“编码-解码”式结构和跳跃连接的方式（不同于ResNet）实现了对图像的高效处理。通过复现DDPM的代码，我也理解到了论文理论、建模和实际实现、训练模型之间的差别。

此外我初步学习了DDIM的论文，了解了其思路和原理。DDIM的成就在于解决了DDPM多次采样导致训练速度慢的问题。为了解决这一问题将前向过程变为非马尔可夫过程，并在反向过程中先预测x_0，再利用x_0和x_t预测x_t-1，在这样的基础上实现了跳步采样，极大提高了训练速度。并且通过建模，使得DDIM模型可以采用与DDPM模型同样的训练算法。此外模型还引入了超参数sigma，使得我们可以控制生成图像的随机性。

下周任务：继续理解DDIM，理解DDIM创新点的数学原理。并阅读SDE的论文。

## 第四周
### 周总结
DDIM:本周深入理解了DDIM的思想和数学原理，并与DDPM进行对比，加深了对DDPM的理解。我深入思考了DDIM和DDPM在能否跳步采样上的区别以及内在原理，DDIM能够跳步的原因正在于其舍弃了马尔可夫性质，其反向过程根据重参数化公式先预测x_0，再利用前向过程的公式q预测x_k，由于前向过程是已知的，k可以任意取值；而DDPM反向过程和优化目标要求马尔可夫性质成立，并且步数T必须足够大才能导致前向过程收敛到高斯噪声，因此DDPM无法跳步，其训练速度很慢。在我的理解中，DDIM更像一种新的采样方法，我们只需要修改DDPM模型中的部分参数，就可以实现加速采样。本篇论文在理论的最后部分将DDIM同Neural ODE联系的起来，可以看到当超参数sigma=0时，整个过程实际变为了一个Neural ODE。（这与后面Score-based中的理论很相近）因此，DDPM/DDIM所搭建的扩散模型可以认为是一个随机微分方程的解（即一个随机过程），当DDIM中的超参数sigma=0时，该过程变为确定性过程（即ODE）。这也启示我们可以从微分方程的视角去研究扩散模型。
SGM：本周补齐了SDE和Langevin方程的数学基础，并学习Yang Song的Score-based Model(SGM)讲解视频。SGM的目的是高效实现Probability Evaluation和Flexible Models。采用得分函数避免了复杂的归一化常数的计算，并在得分匹配（优化目标的推导）上采用了切片法，通过分部积分变换得到了效率更高的损失函数：只需要在前向和反向计算图中各添加一层向量内积层即可。同时也提到了去噪得分匹配（DSM），根据DSM的原理可以知道去噪的方向就是得分函数（即梯度）的方向（这也与DDPM反向过程预测噪声的理念相合）。在生成模型阶段，我们可以利用训练所得的得分函数进行采样，迭代生成图片。作者提到了朗之万动力学(SDE)采样可以避免样本仅收敛于少数极值点(ODE)，但是这种算法却无法生成有效的图片，原因在于得分函数在采样时会忽略原始分布中概率密度低的区域，因此仅在密度高的区域有较好的拟合效果。这个问题的解决留待下周。
笔记：https://github.com/PeiyangFantasist/Learn-Notes-of-DL-and-CV
下周任务：继续消化Yang Song讲解视频中的内容，并学习原论文。之后若还有时间则从余下的论文中选择一个方向开始钻研。

## 第五周
### 周总结
SGM: 本周接着上周的内容，看完了原论文(Score-based Model, Yang Song)。单纯地结合朗之万与得分函数算法无法收敛到有效图片的原因是，损失函数是关于p_data的期望，在p_data密度低的区域中，该损失函数效果很差，导致朗之万采样的效果很差（样本点很可能被错误的梯度影响，无法收敛到p_data中的高概率点）。因此我们考虑加入不同等级的噪声来干扰原分布，并改造得分函数神经网络为s(x,\sigma)，在这种情况下得分函数对加噪后的原始分布的拟合效果非常好。因此在生成模型（类似反向）中，我们利用这种方法拟合出每一步的得分函数，然后从纯噪声开始迭代（执行朗之万采样），这样就能保证我们的样本点在得分函数的引导下一定能收敛到原始data分布中的高概率区域。
如果我们把上述过程连续化，我们就得到了一个随机微分方程，如果将随机项去掉，我们就得到了所谓的概率流ODE，这个ODE仅由得分函数和原始采样的点共同决定，因此可以将ODE识别为一种编码，这种编码是噪声与原始数据中的点的一一映射。我们还可以将DDPM给SDE化，进而发现DDPM和文中的SMLD在SDE下拥有类似的形式，只是方差，均值不同。本文构建的得分函数模型还可以用于可控生成，因为条件生成的分布的得分函数就是非条件分布的得分函数。总结一下，这个工作的亮点就是：1.得分函数 2.对加噪操作的解释 3.构建SDE框架统合了DDPM等模型
LDM: 本周抽了一点时间阅读LDM论文(High-Resolution Image Synthesis with Latent Diffusion Models)，这篇文章的结合了VQGAN, DDPM等模型，将像素空间的图像x编码为潜空间E(x)，在潜空间中使用DDPM架构，并在反向去噪前嵌入“输入”y，以及交叉注意力机制，最后在潜空间中去噪得到输出。
笔记：https://github.com/PeiyangFantasist/Learn-Notes-of-DL-and-CV
下周任务：把与LDM模型关联大的VQGAN和Transformer粗略地学一下，然后弄清楚这篇文章的原理，和前几周一样写一篇note出来。

## 第六周
### 周总结
本周先搞懂了Transformer的原理（位置编码，多头注意力机制等），然后对比DDPM的理论，理清了LDM论文的全过程。
LDM的总体结构分为感知压缩编码器，前向扩散过程，文本等条件信息的编码器，嵌入交叉注意力模块的去噪U-Net，以及解码器。
本文的感知压缩模型继承自VQVAE和VQGAN，也就是一种离散潜空间，通过codebook编码的方式严格限制了潜空间中的”距离”，避免出现VAE的后验坍塌问题（编码器“偷懒”使得KL散度项被忽略，模型难以学到数据中的有效信息），离散化处理也有助于编码器提取更有意义的特征；同时引入了GAN的判别器进行对抗训练避免了图片的局部模糊现象，实现高分辨率图像的生成；在感知压缩模型中，损失函数中的重构项从均方误差被替换为感知损失，可以促使模型关注图像的整体感知结构。
本文在潜空间中搭建DDPM模型，其前项过程与DDPM一致。对反向过程的改动体现在U-Net架构和损失函数上，DDPM的U-Net只会接受时间位置编码，然后通过数个卷积层或自注意力机制进行去噪，而LDM引入交叉注意力机制，输入嵌入了多模态条件的编码,融合图文之间的特征关系（Attn(Q,K,V)输出的矩阵可表征两者特征对特征的关系）。对于损失函数，依然采用DDPM预测噪声的形式，但预测的是条件噪声，这相当于在DDPM损失函数的基础上作出了如下改动：进行条件去噪，在给定标签的条件下，去噪图片。因此我们训练出的结果会是：反向过程在保证条件y实现的情况下，尽可能地使去噪后的图片\hat{x}接近原始图片x。
总结：本篇论文的亮点在于结合了多种工作，实现了潜空间中的条件扩散模型，实现了加速生成，多模态，高分辨率等目标。
下周任务：阅读论文CLASSIFIER-FREE DIFFUSION GUIDANCE