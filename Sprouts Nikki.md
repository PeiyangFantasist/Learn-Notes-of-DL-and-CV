# Sprouts Nikki

## 第一周

### #1 Feb 10
今天部署了 Pytorch 环境，补全了自己的深度学习基础知识。学习了 tensor 类的索引、切片、内存分配、GPU使用等操作。并通过代码实践搞懂了张量的轴这一概念（axis）。此外，学习了梯度，上手证明了李沐老师教材中的一些数学结论。了解了自动求导的原理（计算图，以及衍生出的正向/反向传播）。结合以前学习c++时了解的内存知识，初步建立起了内存分配的想法。
### #2 Feb 11
在没看李沐老师讲解的情况下，自己尝试实现了一个简单的线性回归模型，实现了前向计算和反向传播。理解了整个模型构建的流程。
### #3 Feb 12
跟随李沐老师的讲解实现了线性回归模型。
### #4 Feb 13
休息
### #5 Feb 14
累死了，只看了点softmax
### #6 Feb 15
softmax完结
### #7 Feb 16
顶多看一点论文开头

### 周总结
本周主要完成了深度学习所需环境的搭建以及深度学习基础的学习。首先，本周掌握了 PyTorch 库的一些基本使用方法，tensor 类的索引、切片、内存分配、GPU使用等操作。并通过代码实践搞懂了张量的axis这一概念。此外，学习了梯度，并尝试证明了李沐老师教材中的求梯度公式。在学习 PyTorch 的过程中，我结合以前学习C++的内存部分章节时的知识，了解到了内存分配的重要性以及 PyTorch 中张量的内存分配方式，开始理解深度学习过程中处理内存分配的想法和重要性。

此外，为了给后续的学习打下基础，本周还用torch学习并实现了线性回归和softmax回归。通过这两个模型，我大概了解到了深度学习模型搭建的基本思路：对于处理后的数据，采用一个模型（从而选定建模所用的函数和参数），并定义一个损失函数，用于指导参数更新的“方向”，从而完成训练过程，最后再通过精确率或统计误差等统计量来衡量模型的好坏。相比传统的机器学习，深度学习多出了损失函数和参数更新的环节，并给出了寻找更有效的参数的方法：梯度下降法。

最后，本周初步阅读了DDPM的论文，了解了DDPM的核心思想，也就是逐步加入噪声（前向），然后让模型逐步去噪（反向）。

下周任务：往后学习多层感知机，深化对深度学习的理解，同时继续阅读DDPM的论文。交替学习基础和论文。

## 第二周
### #8 Feb 17
阅读了GAN的论文。
### #9 Feb 18
学习了MLP的原理，阅读了VAE的论文。
### #10 Feb 19
学懂了VAE

### 周总结
本周先学习了多层感知机的基础，略读了GAN，VAE的原理和论文，细读了DDPM这篇论文，并推导了其中的大部分公式。在MLP的学习过程中了解到了MLP的基本架构以及重要概念：隐藏层和激活函数。并在后续的学习过程中了解了一些如何处理过拟合的方法，比如以约束参数为基本思想的正则化方法（又分为直接约束参数值的权重衰减法和通过改变神经网络结构避免过拟合的dropout法）。在学完MLP后我彻底理解了深度学习中常说的“前向和反向”两个概念，加深了对DL流程的理解。以上的学习都为接下来三篇论文的阅读打下了基础。
在图像生成的工作中，我们的流程往往是训练一个神经网络，让它能够生成一个概率分布去逼近原有图像的概率分布，再进行参数更新。而真实的概率分布往往十分复杂，因此需要建立一些模型来简化这一过程。比如，GAN采用一个对抗网络通过minmax博弈训练生成器和判别器，从而绕开了对原有概率分布的直接建模；但其缺点也十分明显————没有传统意义上的“损失函数”，从而没有一种客观的衡量来评判图像生成好坏的程度。VAE采用的方法是对隐变量进行建模，它假设图像x的生成由隐变量z控制，以此定义一个负责学习后验分布的编码器和学习先验分布的解码器。最后通过KL散度来衡量损失函数。VAE的数学技巧与DDPM也比较相似，都用到了变分推断和重参数化技巧，我认为这两点是十分重要的，尤其是重参数化技巧在后续的工作（DDPM）中也起到了十分重要的作用。
DDPM的核心流程是“前向加噪，后向去噪”，在马尔可夫性质下，可以证明原图像经历一系列正态分布的转移后，最终会迭代为一个简单的正态分布，这就是前向的过程。而后向考虑的也是在马尔可夫性质下，利用一系列正态分布去逼近原始的图片。在讨论损失函数时，作者的思路十分巧妙，先定义负对数似然，然后利用变分推断化为证据下界（ELBO），之后通过马尔可夫性质（引入q分布）转化为一系列正态分布的KL散度之和，这样问题就从研究复杂分布变为了研究正态分布的均值（该KL散度有解析解），最后再利用重参数化技巧，把问题变为预测噪声，因此整个损失函数化为了噪声ε的MSE。这篇文章的高光点不仅在于提出了一种全新的编码器，更在于给出了一种新的损失函数。
详细笔记：https://github.com/PeiyangFantasist/Learn-Notes-of-DL-and-CV
下周任务：试着阅读DDIM论文，并尝试跟着hugging face上的教程学习扩散模型的代码实现。

## 第三周
### 周总结
本周在本地复现了DDPM的代码，执行了一次模型训练。在学习中了解到了位置编码的实现思路，理解了DDPM是如何把时间步作为参数传给神经网络的。同时，为了完成神经网络的搭建，我还学习了残差神经网络(ResNet)和U-Net。残差神经网络通过引入跳跃连接————即让中间层的学习目标变更为残差函数，从而避免了梯度消失和网络退化的问题，解决了深层网络的性能劣于浅层网络的问题。而U-Net则通过上下采样的“编码-解码”式结构和跳跃连接的方式（不同于ResNet）实现了对图像的高效处理。通过复现DDPM的代码，我也理解到了论文理论、建模和实际实现、训练模型之间的差别。

此外我初步学习了DDIM的论文，了解了其思路和原理。DDIM的成就在于解决了DDPM多次采样导致训练速度慢的问题。为了解决这一问题将前向过程变为非马尔可夫过程，并在反向过程中先预测x_0，再利用x_0和x_t预测x_t-1，在这样的基础上实现了跳步采样，极大提高了训练速度。并且通过建模，使得DDIM模型可以采用与DDPM模型同样的训练算法。此外模型还引入了超参数sigma，使得我们可以控制生成图像的随机性。

下周任务：继续理解DDIM，理解DDIM创新点的数学原理。并阅读SDE的论文。

## 第四周
### 周总结
DDIM:本周深入理解了DDIM的思想和数学原理，并与DDPM进行对比，加深了对DDPM的理解。我深入思考了DDIM和DDPM在能否跳步采样上的区别以及内在原理，DDIM能够跳步的原因正在于其舍弃了马尔可夫性质，其反向过程根据重参数化公式先预测x_0，再利用前向过程的公式q预测x_k，由于前向过程是已知的，k可以任意取值；而DDPM反向过程和优化目标要求马尔可夫性质成立，并且步数T必须足够大才能导致前向过程收敛到高斯噪声，因此DDPM无法跳步，其训练速度很慢。在我的理解中，DDIM更像一种新的采样方法，我们只需要修改DDPM模型中的部分参数，就可以实现加速采样。本篇论文在理论的最后部分将DDIM同Neural ODE联系的起来，可以看到当超参数sigma=0时，整个过程实际变为了一个Neural ODE。（这与后面Score-based中的理论很相近）因此，DDPM/DDIM所搭建的扩散模型可以认为是一个随机微分方程的解（即一个随机过程），当DDIM中的超参数sigma=0时，该过程变为确定性过程（即ODE）。这也启示我们可以从微分方程的视角去研究扩散模型。
SGM：本周补齐了SDE和Langevin方程的数学基础，并学习Yang Song的Score-based Model(SGM)讲解视频。SGM的目的是高效实现Probability Evaluation和Flexible Models。采用得分函数避免了复杂的归一化常数的计算，并在得分匹配（优化目标的推导）上采用了切片法，通过分部积分变换得到了效率更高的损失函数：只需要在前向和反向计算图中各添加一层向量内积层即可。同时也提到了去噪得分匹配（DSM），根据DSM的原理可以知道去噪的方向就是得分函数（即梯度）的方向（这也与DDPM反向过程预测噪声的理念相合）。在生成模型阶段，我们可以利用训练所得的得分函数进行采样，迭代生成图片。作者提到了朗之万动力学(SDE)采样可以避免样本仅收敛于少数极值点(ODE)，但是这种算法却无法生成有效的图片，原因在于得分函数在采样时会忽略原始分布中概率密度低的区域，因此仅在密度高的区域有较好的拟合效果。这个问题的解决留待下周。
笔记：https://github.com/PeiyangFantasist/Learn-Notes-of-DL-and-CV
下周任务：继续消化Yang Song讲解视频中的内容，并学习原论文。之后若还有时间则从余下的论文中选择一个方向开始钻研。

## 第五周
### 周总结
SGM: 本周接着上周的内容，看完了原论文(Score-based Model, Yang Song)。单纯地结合朗之万与得分函数算法无法收敛到有效图片的原因是，损失函数是关于p_data的期望，在p_data密度低的区域中，该损失函数效果很差，导致朗之万采样的效果很差（样本点很可能被错误的梯度影响，无法收敛到p_data中的高概率点）。因此我们考虑加入不同等级的噪声来干扰原分布，并改造得分函数神经网络为s(x,\sigma)，在这种情况下得分函数对加噪后的原始分布的拟合效果非常好。因此在生成模型（类似反向）中，我们利用这种方法拟合出每一步的得分函数，然后从纯噪声开始迭代（执行朗之万采样），这样就能保证我们的样本点在得分函数的引导下一定能收敛到原始data分布中的高概率区域。
如果我们把上述过程连续化，我们就得到了一个随机微分方程，如果将随机项去掉，我们就得到了所谓的概率流ODE，这个ODE仅由得分函数和原始采样的点共同决定，因此可以将ODE识别为一种编码，这种编码是噪声与原始数据中的点的一一映射。我们还可以将DDPM给SDE化，进而发现DDPM和文中的SMLD在SDE下拥有类似的形式，只是方差，均值不同。本文构建的得分函数模型还可以用于可控生成，因为条件生成的分布的得分函数就是非条件分布的得分函数。总结一下，这个工作的亮点就是：1.得分函数 2.对加噪操作的解释 3.构建SDE框架统合了DDPM等模型
LDM: 本周抽了一点时间阅读LDM论文(High-Resolution Image Synthesis with Latent Diffusion Models)，这篇文章的结合了VQGAN, DDPM等模型，将像素空间的图像x编码为潜空间E(x)，在潜空间中使用DDPM架构，并在反向去噪前嵌入“输入”y，以及交叉注意力机制，最后在潜空间中去噪得到输出。
笔记：https://github.com/PeiyangFantasist/Learn-Notes-of-DL-and-CV
下周任务：把与LDM模型关联大的VQGAN和Transformer粗略地学一下，然后弄清楚这篇文章的原理，和前几周一样写一篇note出来。

## 第六周
### 周总结
本周先搞懂了Transformer的原理（位置编码，多头注意力机制等），然后对比DDPM的理论，理清了LDM论文的全过程。
LDM的总体结构分为感知压缩编码器，前向扩散过程，文本等条件信息的编码器，嵌入交叉注意力模块的去噪U-Net，以及解码器。
本文的感知压缩模型继承自VQVAE和VQGAN，也就是一种离散潜空间，通过codebook编码的方式严格限制了潜空间中的”距离”，避免出现VAE的后验坍塌问题（编码器“偷懒”使得KL散度项被忽略，模型难以学到数据中的有效信息），离散化处理也有助于编码器提取更有意义的特征；同时引入了GAN的判别器进行对抗训练避免了图片的局部模糊现象，实现高分辨率图像的生成；在感知压缩模型中，损失函数中的重构项从均方误差被替换为感知损失，可以促使模型关注图像的整体感知结构。
本文在潜空间中搭建DDPM模型，其前项过程与DDPM一致。对反向过程的改动体现在U-Net架构和损失函数上，DDPM的U-Net只会接受时间位置编码，然后通过数个卷积层或自注意力机制进行去噪，而LDM引入交叉注意力机制，输入嵌入了多模态条件的编码,融合图文之间的特征关系（Attn(Q,K,V)输出的矩阵可表征两者特征对特征的关系）。对于损失函数，依然采用DDPM预测噪声的形式，但预测的是条件噪声，这相当于在DDPM损失函数的基础上作出了如下改动：进行条件去噪，在给定标签的条件下，去噪图片。因此我们训练出的结果会是：反向过程在保证条件y实现的情况下，尽可能地使去噪后的图片\hat{x}接近原始图片x。
总结：本篇论文的亮点在于结合了多种工作，实现了潜空间中的条件扩散模型，实现了加速生成，多模态，高分辨率等目标。
下周任务：阅读论文CLASSIFIER-FREE DIFFUSION GUIDANCE

## 第七周
### 周总结
本周学习了CLASSIFIER-FREE DIFFUSION GUIDANCE的论文，了解了生成引导的思想，并将Score-based, LDM模型的理论与之结合。
首先是含分类器的引导理论。条件生成的思想来源于条件得分函数推出的公式，即三者梯度之间的关系：条件生成器=得分函数+分类器（对于每个时间步均有），为了强化分类器，我们引入了超参数s作为分类器的系数，可以证明s的作用相当于原条件分布函数乘上了s-1次幂的条件分类函数，因此，在条件分类函数连乘的作用下，原概率密度会被集中于条件分类函数的高密度区域，这就是分类器的作用（如论文中的图2）。为了实现这种条件模型，我们需要额外训练分类器p(z_λ|c)，该分类器要做的不仅是接受原始图像进行分类，还需对不同信噪比的噪声图像进行分类，这意味着我们必须自行训练一个分类器而不能使用预训练的分类数据。（为简便起见，下面将不含超参数s的生成器称为“p(x|y)”，含s的称为“p'(x|y)”）
因此，作者引出了无分类器的引导模型，我们联立p和p'的两个方程消去分类器，得到一个线性加权方程lg p'=(1-s)lg p(x) + s lg p(x|y)，从而推导出原文公式(6)：现在只需要联合训练条件注入后的噪声预测网络和非条件的噪声预测网络即可。为了实现这一目标，本文引入超参数p_uncond作为一个概率，在训练过程中随机地将条件“抹去”，从而训练一个通用的参数神经网络ε(z_λ,c)。采样算法的思路和朗之万动力学的思想一致。从而在这种模型中，只需要输入标注好的带分类标签数据(x,c)，只进行一次训练就可以实现条件生成了。
笔记：https://github.com/PeiyangFantasist/Learn-Notes-of-DL-and-CV/blob/main/CLASSER-FREE-GUIDANCE.ipynb
下周任务：鉴于理论方向的论文基本已经看完，下周开始选取具体的一些应用方向进行学习。下周学习Latent Consistency Models

## 第八周
### 周总结
本周学习了Latent Consistency Models的论文。LCM模型综合了CM（一致性模型）、LDM（潜在扩散模型）、CFG、DDIM等模型的特点。其亮点在于将一致性蒸馏、无分类引导和潜在空间结合起来，实现了快速生成高质量图像。
本文从SGM模型的概率流ODE出发，因为在SD等模型中，反向过程实质上是求解基于去噪得分匹配的微分方程，因此我们考虑一个函数，给定采样点和时间步，能够一步到位地输出方程的解，而无需多次迭代。即一致函数，一致函数需要满足对不同时间步具有相同输出，并且在时间步为0（或小正数eps）时，输出为原始值。在Song的论文中，已经实现了一致蒸馏的训练算法：计算相邻两时间步的模型输出来检验模型的一致性。其中相邻步的点只需要通过欧拉法对方程进行一步预测得到，大大减少了计算量。
本文基于CM，将模型引入潜在空间进行蒸馏，并且实现了对CFG（无分类器模型）的蒸馏，融合了两者的加速优点。此外，本文改进了CM的损失函数，将原来的“相邻步比较”改为“间隔k步的比较”，这是因为SD模型往往拥有较长的时间步，因此相邻两步之间的差距本就很小，会导致算法收敛速度过慢。本文在一步预测这一细节上也进行了改进，采用了DDIM等支持跳步的ODE求解器。
下周计划：继续阅读模型加速邻域的论文，如2024-NeurIPS-Rethinking the Role of the Encoder for Diffusion Model Inference

## 第九周
### 周总结
本周顺着自己的兴趣学习了加速扩散模型的另一种方法：量化，阅读了Post-training Quantization on Diffusion Models CVPR 2023和Q-Diffusion Quantizing Diffusion Models ICCV 2023两篇论文。量化方法从神经网络的激活分布和权重分布入手，选取缩放因子和量化零点进行操作，从而实现模型的轻量化与高效化。然而扩散模型的量化与传统量化不同的是：DDPM的U-Net网络嵌入了时间步导致每一步的激活分布截然不同，这带来了校准数据集采集的问题；且由于U-Net被划分为多个具有相对独立功能的块，这导致我们必须开发一种能处理神经网络层间依赖关系的量化校准方法；并且由于U-Net中存在跳跃连接将提取深层特征的通道和提取浅层特征的通道相连接，这也会导致激活分布出现异常现象。因此，两篇论文的核心都是围绕着上述困难。
PTQ4DM通过三个实验结果得出了三个结论：时间步、U-Net 层间的分布差异巨大，因此不能简单地采取某一固定时间步生成的样本来校准；应当采用反向去噪生成的样本作为量化校准集；应当使采用的样本时间步更小，因为较小时间步的样本更接近于真实分布。基于以上结论提出了“正态分布时间步长校准算法”：即从均值小于T/2的正态分布中采样，取整截断后得到一组时间步，然后利用全精度网络得到该组时间步对应的去噪器输出，从而得到校准数据集。该算法从时间步的层面解决了上述三个结论中的问题，并成功地将模型压缩到了8位。
QDM的工作则更加深入，首先是对全时间步下激活分布差异的观察，作者发现相邻时间步的激活分布是十分相近的，因此可以用一个时间步下的分布来近似其周围的时间步，对于此问题，作者提出了校准数据集应当均匀、等步长地从全精度噪声网络中采样。另外，QDM的观察深入到了U-Net的层间关系中，即跳跃连接造成解码器中某几个层拥有极度不均匀的激活分布和权重分布，对于分布极度不均匀的权重进行量化（线性缩放并取整），极有可能导致大误差。对于该问题，作者认为没有必要再使用训练后量化的方法，转而采用了“先量化，再跳跃连接”的方法，并在实验中证明了其效果。最后，对于校准问题，传统PTQ常常采用逐层校准的方法，即逐层比较重建分布与全精度输出分布之间的重建误差，而作者在本文中提出按块校准的方法：将U-Net中的卷积/残差块视作一个整体块，从而统一对其进行校准，这样保证了卷积/残差块作为一个整体的误差最小，而非单层的误差最小。
本周为理解两篇论文，也复习并更深入了解了U-Net的架构以及DDPM神经网络的特性，以上所有内容均总结为了笔记：https://github.com/PeiyangFantasist/Learn-Notes-of-DL-and-CV/blob/main/Quantized_DM.pdf
下周安排：学习Faster Diffusion: Rethinking the Role of the Encoder for Diffusion Model Inference

## 第十周
### 周总结
本周阅读了论文Faster Diffusion: Rethinking the Role of the Encoder for Diffusion Model Inference，这篇文章和上周阅读的QDM那篇文章的出发点比较相似，都着眼于去噪U-Net网络内部各特征通道，时间步之间的分布，构建一种加快模型推理速度的方法。本篇论文对特征分布进行研究得出了三个结果：1.编码器的特征随时间步变化程度小，并且深层特征变化幅度更小，而解码器很大；2.按特征通道进行全时间步下的F范数（可用于表征特征与通道的关系），发现编码器在层间的特征演化幅度也很小，而解码器很大；3.计算特征标准差，也证实了上述结果。因此，作者认为，为了加快模型速度，可以简化编码器传播：选出某些时间步作为关键时间步，其余非关键时间步的编码器输出用相邻关键步的输出特征来替代。为了对应原实验结果中“时间步数较高时特征变化较快”这一点，我们可以非均匀地采取关键步。这样在保持原有采样步数的情况下，加快了编码器的速度。同时，对于非关键时间步的时间步嵌入、编码器前向传播等操作可以并行计算，大大减少了推理速度。
此外，作者也注意到了缺少真实的解码器信息传入导致图片纹理模糊的问题，因此作者采取了“注入初始噪声信息”的方法，即用推理步骤的初始噪声作为补偿加入到解码器获得的信息中，解决了这一问题。
下周任务：由于扩散模型及加速模型方向的论文已有一定积累，下周准备学习LDM的代码实现。